{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "337befe0",
   "metadata": {},
   "source": [
    "# Homework 2 - 95-791 Data Mining (Fall 2021) \n",
    "## Name: \n",
    "#### Due: Friday, November 12th, before 1PM (EST)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2783fe",
   "metadata": {},
   "source": [
    "### Changing the author field and file name.\n",
    "\n",
    " (a) Change the `name:` field on the Jupyter document from Your Name Here to your own name.\n",
    "\n",
    " (b) Rename this file to \"Homework2_F21_YourHameHere.ipynb\", where YourNameHere is changed to your own name.\n",
    "\n",
    "\n",
    "### Installing and loading packages\n",
    "\n",
    "Before you begin this Homework make sure you have installed all the required libraries. Load the libraries as indicated below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ece2b0a",
   "metadata": {},
   "source": [
    "You only need to install libraries once.  Once they're installed, you may use them by **importing** the libraries using the `import` command.  For today's lab, you'll want to run the following code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48347bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut, KFold, cross_val_score\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import r2_score \n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e0693c",
   "metadata": {},
   "source": [
    "For this problem we’ll be working with two years of the bicycle sharing systems for New York City (Citibike). The dataset contains daily bike trip counts, along with daily measurements on environmental and seasonal information that may affect the bikesharing.\n",
    "\n",
    "Here’s information on what the variables mean.\n",
    "\n",
    "- trips - daily total number of bike trips taken (all stations) - target variable.\n",
    "- precipitation - daily inches of rain\n",
    "- snow_depth - daily inches of snow. Accoding to NOAA \"Determine the depth of the new and old snow remaining on the ground at observation time\".\n",
    "- snowfall - according to NOAA \"Measure and record the snowfall (snow, ice pellets ) since the previous snowfall observation (24 hours).\"\n",
    "- max_temperature - daily maximum temperature in Farenheit (highest temperature reached)\n",
    "- min_temperature - daily minimum temperature in Farenheit (lowest temperature reached)\n",
    "- average_wind_speed - measured hourly in mph and averaged for daily value\n",
    "- year \n",
    "- holiday\n",
    "    - True\n",
    "    - False\n",
    "- stations in service - docking stations working per day\n",
    "- weekday\n",
    "    - True\n",
    "    - False\n",
    "- weekday_non_holiday\n",
    "    - True\n",
    "    - False\n",
    "\n",
    "More details on snow measurements [here](https://www.weather.gov/gsp/snow)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0197973",
   "metadata": {},
   "source": [
    "### Question 1. Data Processing [3 pts]\n",
    "Let's start by loading and pre-processing our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1741a816",
   "metadata": {},
   "source": [
    "**1)a) Load the `bikes` dataset into a dataframe called `bikes`. Check that there are no missing values in your dataset. If they are, take care of them appropriately. Print the first five rows.** [0 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52b43d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b25f5fd",
   "metadata": {},
   "source": [
    "**1)b) We need to encode our qualitative predictors before we proceed into any modeling. Predictors `holiday`, `weekday`,`weekday_non_holiday` are type boolean, therefore you must cast them to be numerical. For predictor `season` you will either have to create [dummy variables](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html) and append them to your dataframe or map each season to a different number (spring:1,summer:2,fall:3,winter:4). Print the first five rows of your dataset.** [2 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06982959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab3a3e3",
   "metadata": {},
   "source": [
    "**1)d) Split your dataframe into `X` and `y` dataframe, and then split into `X_train`, `X_test`, `y_train` and `y_test`. Use a 80-20 ratio for the split and a random_state=(your birthday month). Print out your y_test.** [1pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "490938b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0413b6d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 2 - Linear vs Polynomial Models [10  pts]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2d1c14",
   "metadata": {},
   "source": [
    "**2)a) Use Scikit-learn to train a Linear Regression on your dataset. Print out the train MSE and train $R^2$, the test MSE and test $R^2$. How good of a fit is your Linear Model?**[5 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28525d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278df663",
   "metadata": {},
   "source": [
    "--> Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5da2ab",
   "metadata": {},
   "source": [
    "**2)b) Use Scikit-learn to train a Polynomial Regression on your dataset. Iterate through degrees 1 to 6, and for each degree print out the degree, its train MSE and its test MSE. Are any of the MSEs better than a Linear Regression? What can you comment on the results between the Train and Test MSEs?**[5 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c55b735",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2120b4",
   "metadata": {},
   "source": [
    "--> Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc41c480",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 3 - Variable Selection [15 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30af4c8",
   "metadata": {},
   "source": [
    "Sequential Feature Selection (SFS) in the equivalent of Forward or Backwards stepwise selection in scikitlearn. SFS will choose the best new feature in each iteration and add it to the model. To measure and select the best feature to add to the combination in each SFS uses the cross-validation score. You can find the full description of SFS [here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html?highlight=sequential%20feature#sklearn.feature_selection.SequentialFeatureSelector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "881c8d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bd8e65",
   "metadata": {},
   "source": [
    "Let's try SFS as a Forward stepwise selection. Look a the description below for SFS and apply sfs to the boston dataset. For this question, use a linear model, pick the number of features to select, do forward sfs, use the MSE, and a cv with k=10.\n",
    "\n",
    "**SequentialFeatureSelector**\n",
    "\n",
    "- estimator - this will be a certain model. For example LinearRegression()\n",
    "- n_features_to_select - Default is `None`, which means half of the features are selected.\n",
    "- directions - `backward` or `forward`\" selection.\n",
    "- scoring - take a loook at the [metrics and scoring](https://scikit-learn.org/0.24/modules/model_evaluation.html#scoring-parameter) reference. A common metric for regression would be `neg_mean_squared_error` (negative MSE)\n",
    "- cv - cross-validation. Default=`None` will yield a 5-fold cross validation. Otherwise change this number.\n",
    "\n",
    "*Note: You do not need to split up your dataset, you are choosing the best features and SFS comes with CV*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2745ab",
   "metadata": {},
   "source": [
    "**3)a)Complete and run the code below. Select four features with the SFS build a LinearRegression. Use a `k=10` for your cross validation. What is the $R^2$ of this model?**[4pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "504de455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model= LinearRegression()\n",
    "#sfs = SequentialFeatureSelector(model, \n",
    "#                                n_features_to_select = features_selected, \n",
    "#                                direction=\"forward\",\n",
    "#                                scoring='neg_mean_squared_error',\n",
    "#                                cv= k) \n",
    "#sfs = sfs.fit(X,y)\n",
    "#feature_names= #column names for X\n",
    "#print(\"Features selected by forward sequential selection: \"+str(feature_names[sfs.get_support()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b01a1a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e9aa3e",
   "metadata": {},
   "source": [
    "**3)b) Use 3)a) and put it inside a loop, from 1 to your total number of features). Print the results (Number of features and features selected). What are the features selected when the model has 6 features?** [3pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83df44ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1393e837",
   "metadata": {},
   "source": [
    "--> Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6195a775",
   "metadata": {},
   "source": [
    "**3)c) Use your loop from 3)b) and add a [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) to the loop. For each iteration print the predictors selected and the average CV. Save all the CV errors in an array.** [4pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22fe77bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1564dd99",
   "metadata": {},
   "source": [
    "**3)d) Use the CV errors you collected from 3)c) and plot a graph of number of predictors vs CV error. Calculate the lowest CV error and draw a vertical line on your plot to indicate this number. What is the number of predictors that corresponds to the lowest CV error?** [4pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cb38b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba651034",
   "metadata": {},
   "source": [
    "--> Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50184874",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 4 - Regularized Regression [ 12 pts]\n",
    "\n",
    "This question is very similar to what we did in Lab 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7d38dc",
   "metadata": {},
   "source": [
    "**4)a) Train a [Ridge regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) on your dataset. Different to our Lab 2, use the `cross_val_score` (instead of the test and train MSE), and plot two graphs: coefficients vs alphas, and CV_error vs alphas. In the second graph find the lowest CV_error and draw a vertical line on the graph to indicate the alpha that corresponds to this value. What is your best alpha?**[3 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a3c90f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba0f49d",
   "metadata": {},
   "source": [
    "--> your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ea16e4",
   "metadata": {},
   "source": [
    "**4)b) Repeat your Ridge regression, but using RidgeCV, and print out the best alpha for this model. Is this alpha the same or close enough to the alpha calculated in 4)a)?**[3 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71f58a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2064dd",
   "metadata": {},
   "source": [
    "--> your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144a304a",
   "metadata": {},
   "source": [
    "**4)a) Train a [Lasso regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) on your dataset. Different to our Lab 2, use the `cross_val_score` (instead of the test and train MSE), and plot two graphs: coefficients vs alphas, and CV_error vs alphas. In the second graph find the lowest CV_error and draw a vertical line on the graph to indicate the alpha that corresponds to this value. What is your best alpha?**[2 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a112ba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6005e2ab",
   "metadata": {},
   "source": [
    "--> your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd0391e",
   "metadata": {},
   "source": [
    "**4)d) Repeat your Lasso regression, but using LassoCV, and print out the best alpha for this model. Is this alpha the same or close enough to the alpha calculated in 4)c)?**[2 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a1fdf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e9c887",
   "metadata": {},
   "source": [
    "--> your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7c7fe0",
   "metadata": {},
   "source": [
    "**4)e) Print out the best results from your Lasso, Ridge and Linear regression. Which model works best with your data?** [2 pts]\n",
    "\n",
    "*Note: If you didn't save your results from all your models, go back and modify your code from the previous questions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7093b205",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3484a95a",
   "metadata": {},
   "source": [
    "--> your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e412f665",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 5 - Classifications and Comparisons [ 10 pts]\n",
    "\n",
    "For this question we will another data set from [Kaggle](https://www.kaggle.com/prathamtripathi/drug-classification), related to Drug classification. Go ahead, download and read this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be429c0",
   "metadata": {},
   "source": [
    "**5)a) Begin by creating a training and testing datasest from our `df_drugs` dataset, with a 70-30 ratio, and random_state=1.** [1 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7c61c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dbf207",
   "metadata": {},
   "source": [
    "**5)b) Train a KNN model for question 5)a), and print out its confusion matrix. How well did your model perform? Did it classify all classes the same? What was the accuracy? Include comments to explain your code.** [2 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d49d04ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aee0dc",
   "metadata": {},
   "source": [
    "--> Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e4d21d",
   "metadata": {},
   "source": [
    "**5)c) Use cross validation to determine what is the optimal number of neighbors for your KNN model. Plot a graph of # neighbors vs accuracy of your model. Include comments to explain your code.** [2 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94c7488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d235c1d",
   "metadata": {},
   "source": [
    "**5)d) Now that you have the optimal number of neighbors, re-train your model with this information. What is the new accuracy of your model? Print out the confusion matrix of this model and another metric that will help you justify how good this model is. Include comments to explain your code.** [2 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f57733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cbd134",
   "metadata": {},
   "source": [
    "--> Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51c1c45",
   "metadata": {},
   "source": [
    "**5)e) Train a [Naive Bayes classifier](https://scikit-learn.org/stable/modules/naive_bayes.html) for your dataset, and print out its confusion matrix. How well did your model perform? Did it classify all classes the same? What was the accuracy? Include comments to explain your code.** [2 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d9d2468",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = GaussianNB()\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd61506a",
   "metadata": {},
   "source": [
    "--> Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60b7109",
   "metadata": {},
   "source": [
    "**5)f) What classification model performed better? Why do you think this happened? Was there a particular class that was more difficult to classify? Justify your answers.** [ 1 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e30231a",
   "metadata": {},
   "source": [
    "--> Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b3edb5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### REFERENCES\n",
    "\n",
    "**List any references you used to complete your homework. Even if they are one of the books assigned for this class. If this section is incomplete you will be deducted 50% of your final grade from this homework.**\n",
    "\n",
    "**Note: if there are no comments to explain your code you will receive 0 in this homework**\n",
    "\n",
    "### Total Score:  --/50\n",
    "\n",
    "### END OF HOMEWORK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e527c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
