{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25bbe275",
   "metadata": {},
   "source": [
    "# Lab 2 \n",
    "## 95-791 Data Mining (Fall 2021) \n",
    "### Name:  Xi Yan\n",
    "#### Date: Friday, October 29th, 2021\n",
    "\n",
    "### Topics covered in this Lab:\n",
    "- Linear and Polynomial Regression with scikit-learn\n",
    "- Ridge and Lasso Regression\n",
    "- Cross Validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00617c96",
   "metadata": {},
   "source": [
    "### Changing the author field and file name.\n",
    "\n",
    " (a) Change the `name:` field on the Rmd document from Your Name Here to your own name.\n",
    "\n",
    " (b) Rename this file to \"Lab2_F21_YourHameHere.ipynb\", where YourNameHere is changed to your own name.\n",
    "\n",
    "\n",
    "### Installing and loading packages\n",
    "\n",
    "Before you begin this Lab make sure you have installed all the required libraries. Load the libraries as indicated below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0445f851",
   "metadata": {},
   "source": [
    "You only need to install libraries once.  Once they're installed, you may use them by **importing** the libraries using the `import` command.  For today's lab, you'll want to run the following code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e2dedac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.express as px\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut, KFold, cross_val_score\n",
    "from sklearn.datasets import load_diabetes\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa19f9db",
   "metadata": {},
   "source": [
    "### 1. Data Processing\n",
    "\n",
    "> For Lab you might want to have your lecture slides and the ISRL textbook (An Introduction to Statistical Learning) open (Chapters 3, 4, and 6) as you go through the exercises. \n",
    "\n",
    "\n",
    "In today's Lab we are going to switch from using statsmodels to [scikitlearn](https://scikit-learn.org/stable/). Scikit-learn works with vectors rather than formulas to compute our models. Follow along the next exercises to learn more.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53dd446",
   "metadata": {},
   "source": [
    "**1)a) Begin by loading the dataset provided into a dataframe called `kc_housing`. Print the first 5 rows of the dataset.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beeeb235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#you code here\n",
    "kc_housing = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dff8b24",
   "metadata": {},
   "source": [
    "**1)b) Verify if there are any missing values. If they are deal with them appropriately. Additionally, drop any columns that might not be relevant to a regression model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6146a888",
   "metadata": {},
   "outputs": [],
   "source": [
    "#you code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "948f16cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#you code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93308ddf",
   "metadata": {},
   "source": [
    "**1)c) We will use `price` as our target variable. Graph the predictor `sqft_living` against the target variable. Use regplot() for this and describe the relationship between those two variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f85fe30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#you code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869b0fdb",
   "metadata": {},
   "source": [
    "--> Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f5e367",
   "metadata": {},
   "source": [
    "**1)d) Split your dataframe into `X` and `y` dataframe. Print your taget variable.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f093474",
   "metadata": {},
   "outputs": [],
   "source": [
    "#you code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4973b226",
   "metadata": {},
   "source": [
    "**1)d) During the lectures we talked about spliting our dataset into training and testing so that we can validate our models. One easy way of doing this is using [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) from scikit-learn. Split your `X` and `y` from the kc_housing dataset into `X_train`, `X_test`, `y_train` and `y_test`. Use a 75-25 ratio for the split and a random_state=1. Print out your y_test.**\n",
    "\n",
    "**Hint: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=your_number, random_state=your_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b93e9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#you code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec39c92d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. Linear and Plynomial Regression with Scikit-Learn\n",
    "\n",
    "Linear Regression with scikit-learn requires you to have your data in vector (array) form rather than formulas (like statsmodels. Look at the steps below to get an idea.\n",
    "\n",
    "We import LinearRegression from scikit-learn:\n",
    "```\n",
    "from sklearn.linear_model import LinearRegression\n",
    "```\n",
    "\n",
    "Most models on scikit-learn are python classes, which means we'll have to create an object of this class, and we'll have access to its attributes and methods.\n",
    "```\n",
    "lm = LinearRegression()\n",
    "```\n",
    "\n",
    "The next step is fitting our dataset to our `lm` model. So far its just an empty object of class LinearRegression. Pretend we already have a dataset `df` with all our data. We need to separate our dataset into `X` and `y` before fitting it to our model.\n",
    "```\n",
    "X = df.drop(['y'],axis=1)\n",
    "y = df['y']\n",
    "```\n",
    "\n",
    "Once separated we can use our `X` and `y` in our `lm` model:\n",
    "```\n",
    "lm.fit(X,y)\n",
    "```\n",
    "\n",
    "From the documentation of [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html?highlight=linear%20regression#sklearn.linear_model.LinearRegression) you'll see that there are a few methods associated with this class:\n",
    "- fit(X, y[, sample_weight])\n",
    "- get_params([deep])\n",
    "- predict(X)\n",
    "- score(X, y[, sample_weight])\n",
    "- set_params(**params)\n",
    "\n",
    "As well as a few attributes:\n",
    "- coef_\n",
    "- rank_\n",
    "- singular_\n",
    "- intercept_\n",
    "- n_features_in_\n",
    "- feature_names_in_\n",
    "\n",
    "There are also parameters you can modify when creating your object from class LinearRegression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abf42c4",
   "metadata": {},
   "source": [
    "**2)a) Use your training dataset to fit them into a LinearRegression (with scikit-learn) and print out the coeficients of your model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a470457",
   "metadata": {},
   "outputs": [],
   "source": [
    "#you code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c5da9e",
   "metadata": {},
   "source": [
    "**2)b) You can calculate the $R^2$ of your model by using the method `score` from LinearRegression. Use your model from 2)a) to print out the $R^2$ of your training set and the  $R^2$ of your testing set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92f8478b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Training R-squared: \", lm.score(#you code here))\n",
    "#print(\"Testing R-squared: \", lm.score(#you code here))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a653d6",
   "metadata": {},
   "source": [
    "**2)c) How good is your model based on your answer from 2)b)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2885b9",
   "metadata": {},
   "source": [
    "Better than a coin flip! But could be better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba93750c",
   "metadata": {},
   "source": [
    "**2)d) Use the [`mean_squared_error`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) method (package already imported) to calculate your training and testing MSE.**\n",
    "\n",
    "**Hint: You'll have to calculate the predicted values of your model, both with your train and test datasets, and then calcualte their corresponding MSEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "529b7fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#you code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12b1355",
   "metadata": {},
   "source": [
    "**2)e) Let's now try a polynomial regression with scikit-learn. We must first transform our X's into [polynomial features](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html). Follow the instructions below and print the coeficients and the test MSE for your polynomial regression (degree=3) model.**\n",
    "\n",
    "Polynomial features is a python class, therefore we must create an object of this class. When creating this object we must specify the degrees of our polynomial. \n",
    "```\n",
    "poly_model = PolynomialFeatures(degree=your_degree)\n",
    "```\n",
    "\n",
    "Once we have our model, we must transform our X's into polynomial form\n",
    "```\n",
    "X_poly_train = poly_model.fit_transform(X_train)\n",
    "```\n",
    "\n",
    "After this step you can follow the same steps as your LinearRegression model. The difference is that you'll plug in your transformed polynomial features instead of your X_train or X_test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aef1a9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#you code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e3c83a",
   "metadata": {},
   "source": [
    "**2)f) Is your test MSE from 2)e) any better than the one obtained in 2)d)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b06fa6",
   "metadata": {},
   "source": [
    "--> Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33abdf17",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. Ridge and Lasso Regression\n",
    "\n",
    "Now that you have warmed up let the fun begin! We will start by looking at Ridge and Lasso Regression. In scikit-learn there are a few ways to compute Lasso Regression and Ridge Regression. For this exercise focus on the following:\n",
    "\n",
    "- [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)\n",
    "- [LassoCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html#sklearn.linear_model.LassoCV)\n",
    "- [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)\n",
    "- [RidgeCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html)\n",
    "\n",
    "The `CV` at the end of Ridge or Lasso means that this model has cross-validation incorporated into its model objects. Therefore the alphas will be internally computed through cross-validation in these classes.\n",
    "\n",
    "*Note: For section you may take the boston dataset or the diabetes dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95591c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a68a384",
   "metadata": {},
   "source": [
    "**3)a) For this first exercise with Ridge regression we are going to apply Ridge() model to the Diabetes dataset. Please complete the code below to iterate through different values of `alpha` and store the values of the errors and coefficients for each alpha.**\n",
    "\n",
    "Steps:\n",
    "- Declare a model with Ridge(). This is the same way we would do it with LinearRegression() model\n",
    "- Fit the model\n",
    "- Use the model to make predictions\n",
    "- Store values of model.coef_ for coefficients\n",
    "- Store the MSE in errors by using the metric `mean_square_error(,)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffbe6b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_ridge = Ridge(normalize=True)\n",
    "#coeficents = []\n",
    "#errors_train = []\n",
    "#errors_test = []\n",
    "\n",
    "#alphas = np.logspace(-5, 5, 200)\n",
    "#for a in alphas:\n",
    "    #model_ridge.set_params(alpha=a)\n",
    "    #you code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4008da3",
   "metadata": {},
   "source": [
    "**3)b) Plot the coefficients and errors you collected in the previous question. You should generate two plots, one of coefficients vs alphas, and another one of MSE (both train and test) vs alphas. You can take inspiration from this [example](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ridge_coeffs.html#sphx-glr-auto-examples-linear-model-plot-ridge-coeffs-py).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "177d9af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#you code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da69bdc3",
   "metadata": {},
   "source": [
    "**3)c) The graphs resemble the ones we talked about in class. What can you comment about these graphs? What seems to be a reasonable value for alpha?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126b5ee9",
   "metadata": {},
   "source": [
    "--> Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e4d9b5",
   "metadata": {},
   "source": [
    "**3)d) Repeat a),b) and c) for Lasso(). Do you see any differences (compared to Ridge) when looking at the graphs?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fcec82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_lasso = Lasso(normalize=True)\n",
    "#coeficents = []\n",
    "#errors_train = []\n",
    "#errors_test = []\n",
    "\n",
    "#alphas = np.logspace(-5, 5, 200)\n",
    "#for a in alphas:\n",
    "#    model_lasso.set_params(alpha=a)\n",
    "#you code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940b6893",
   "metadata": {},
   "source": [
    "--> Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcf622c",
   "metadata": {},
   "source": [
    "**3)e) For this question use the CV version of Ridge (with a cv=10) to model your same dataset. How good is this model for your dataset?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8005fbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_ridgeCV = RidgeCV(cv=10,normalize=True).fit(#your_data)\n",
    "#you code here\n",
    "\n",
    "#print(\"Ridge - best_score: \\n\",model_ridgeCV.best_score_)\n",
    "#print(\"Ridge - best alpha: \"+str(model_ridgeCV.alpha_))\n",
    "#print(\"Ridge - intercept: \"+str(model_ridgeCV.intercept_))\n",
    "#print(\"Ridge - coefficients:\\n \", coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7b3bd7",
   "metadata": {},
   "source": [
    "--> Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6e3619",
   "metadata": {},
   "source": [
    "**3)f) Repeat e) for LassoCV(). How good is this model for your dataset? Was it better or worse than Ridge?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a66a654",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_lassoCV= LassoCV(cv=10, normalize=True).fit(#your_data)\n",
    "#you code here\n",
    "\n",
    "#print(\"Lasso - R-squared: \"+str(model_lassoCV.score(#your_data)))\n",
    "#print(\"Lasso - best alpha: \"+str(model_lassoCV.alpha_))\n",
    "#print(\"Lasso - intercept: \"+str(model_lassoCV.intercept_))\n",
    "#print(\"Lasso - coefficients:\\n \", coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda66a9c",
   "metadata": {},
   "source": [
    "--> Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e0f53e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### If you got to this point you will receive full marks for your Lab 2 (considering that you also attending this Lab session). Nonetheless, we recommend you keep going so that HW2 is easier for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15e102e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4. Cross Validation\n",
    "\n",
    "For this question we will look at K-fold cross validation and LOOCV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2537a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e94132d",
   "metadata": {},
   "source": [
    "**4)a) For this question you are going to apply cross validation to your dataset, while iterating from polynomial degree=1 up to degree=2. Look at the requirements below. How much did this operation take to compute?**\n",
    "\n",
    "Use [KFold()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) with the following parameters:\n",
    "- k of 10.\n",
    "- randome_state=None\n",
    "- shuffle = False\n",
    "\n",
    "Uncomment the lines of code and fill out the missing code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15feb665",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lm = LinearRegression(normalize=True)\n",
    "#characteristics of our CV (as listed above)\n",
    "#cross_val = KFold(n_splits=10, random_state=None, shuffle=False)\n",
    "\n",
    "#start timer\n",
    "#start = time.time()\n",
    "#you code here\n",
    "#computation_time = (time.time()-start)\n",
    "#print(\"Computation time: %5.3f\"%computation_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98275c47",
   "metadata": {},
   "source": [
    "--> Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaf5047",
   "metadata": {},
   "source": [
    "**4)b) Repeat the steps and code from 4)a) but this time use LOOCV instead of Kfolds. How much longer did your LOOCV take compared to your k-fold cross validation?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c2fbb55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#loo_cv = LeaveOneOut()\n",
    "#loo_cv.get_n_splits(housing_X_train)\n",
    "\n",
    "#we are doing the same as before but now our splits/k = n\n",
    "#start = time.time()\n",
    "#loocv = KFold(n_splits=loo_cv.get_n_splits(housing_X_train), random_state=None, shuffle=False)\n",
    "#your code here\n",
    "#computation_time = (time.time()-start)\n",
    "#print(\"Computation time: %5.3f\"%computation_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab95f24",
   "metadata": {},
   "source": [
    "--> Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd345e4d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### END OF LAB 2!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
